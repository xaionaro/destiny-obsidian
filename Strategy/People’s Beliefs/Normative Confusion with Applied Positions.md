## What is it?
Rather than building beliefs from a logical foundation, people tend to inherit [[Constellation of Beliefs|constellations of beliefs]] from their social circles due to [[Social Incentives Dictate Beliefs|misaligned incentives]] that reward beliefs for social validation rather than factual accuracy. Since there was never any work done to arrive at applied positions through some logic, applied positions are quickly and easily confused with moral positions. This results in people confusing their applied positions with the ethical beliefs they hold.
### Examples
Here are some examples expressed as syllogisms, where the first proposition is a moral claim, the second proposition claims to remedy an injury to said moral claim, and the conclusion demands that we follow through to cure the morally egregious injury listed in the first proposition.

Formula: 
P1. Moral injury.
P2. Something that purports to cure the moral injury.
C. A demand to follow P2 to cure P1.

Examples:

P1. Homelessness should not exist in the United States.
P2. Free public housing would solve homelessness.
C. Therefor, we should adopt free public housing.

P1. Civilians should not be targeted in war.
P2. A charge of genocide would force Israel to stop killing civilians.
C. Therefor, we should charge Israel with genocide.

In the prior examples, if you disagree with P2, you necessarily disagree with the conclusion, but your interlocutor will assume that you also disagree with P1 as it becomes intrinsically tied to the conclusion since P2 is considered unquestionable. P2 is most likely unquestionable as it is inherited as part of the constellation of beliefs, meaning the individual has done no work to actually investigate P2, nor do they have any incentive to do so.

This means that if you disagree that we should adopt public housing, it’s because you believe homelessness **should** exist in the United states. Or if you believe we shouldn’t charge Israel with genocide, you believe civilians **should** be targeted in war.
## Limitations
This form of irrationality is incredibly destructive due to how quickly someone is to ascribe to you an entire constellation of beliefs, and likely they will ascribe to you all of the same moral reversals as they have in the singular example you’ve disagreed with. It also hurts your own ability to reason through to good applied positions because you very quickly lose your moral compass when you align yourself with only applied positions.

Here’s an example constellation for someone who’s progressive:
- Systemic racism is real, and is the driver of racial inequities
- Healthcare should be free to all
- Education should be free to all
- Trans rights are unquestionable for all ages
- Housing should not be commodified
- Profit is immoral

Any one of these beliefs could be extracted and expressed in syllogisms as above, and subsequently reversed on you if you disagree with any part of their construction:

P1. Workers shouldn’t be exploited.
P2. Eliminating profit would eliminate most worker exploitation.
C. Profit should be eliminated.

P1. Everyone is entitled to free healthcare.
P2. Medicare-for-all would provide free healthcare for everyone.
C. We should have Medicare-for-all.

A denial of the second premise on either of these would lead to a denial of the conclusion, but most people would see it as a denial of the first premise.
## How to Avoid
Avoiding this pitfall is easy, on paper, but can be difficult, in practice. It’s important to dedicate some time to exploring fundamental moral positions you hold, and then ensuring that your applied positions follow from those moral foundations. If you find that you are constantly accusing others of not having some moral stance simply because they disagree with some policy position, it might be a sign that you’re engaged in some normative confusion, and you need to revisit your fundamental ethical foundations to re-engage with your applied positions.
## How to help others
For others, it might be enough to simply point out that there are other ways of satisfying their fundamental moral positions with different applied positions, but this might be difficult as people often lack fundamental moral positions they’ve thought about and simply inherit their applied positions as part of a constellation of beliefs.